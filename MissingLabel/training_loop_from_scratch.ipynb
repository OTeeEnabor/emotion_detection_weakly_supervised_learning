{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6b64c8",
   "metadata": {},
   "source": [
    "Complete guide to writing low-level training and evaluation loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db30db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Needed\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any, List, Tuple, Union\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "import tensorflow\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4dff337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset start\n",
    "def create_dataset(df):\n",
    "    \n",
    "    X_dataset = []\n",
    "    img_list = df['Path'].tolist()\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        \n",
    "        img = image.load_img(img_list[i])\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255.\n",
    "        X_dataset.append(img)\n",
    "\n",
    "    X = np.array(X_dataset)\n",
    "  # drop unnecessary columns not used for training\n",
    "    y = np.array(df.drop(['Index', 'Filename','Path','Emotion'], axis=1))\n",
    "\n",
    "    return X, y\n",
    "# create dataset end\n",
    "def label_binarizer(y_intensity,threshold_val):\n",
    "    return np.where(y_intensity<threshold_val, 0, 1)\n",
    "def subset_accuracy(y_true,y_pred):\n",
    "    y_true = tensorflow.py_function(label_binarizer,(y_true,0.5), tensorflow.double)\n",
    "    y_pred = tensorflow.py_function(label_binarizer,(y_pred,0.5), tensorflow.double)\n",
    "    return tensorflow.py_function(accuracy_score,(y_true,y_pred),tensorflow.double)\n",
    "\n",
    "def load_model_data(model_path, opt_path):\n",
    "    model = load_model(model_path,custom_objects={\"subset_accuracy\":subset_accuracy})\n",
    "    return model\n",
    "# define Assume Negative loss\n",
    "def loss_an(y_pred, y_true):\n",
    "    bce_loss =tensorflow.keras.losses.BinaryCrossentropy()\n",
    "    return bce_loss(y_pred,y_true)\n",
    "\n",
    "# create model start\n",
    "def create_model(width=224, height=224):\n",
    "  # load pretrained model 'VGG16'\n",
    "    base_model = keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(width, height, 3))\n",
    "    base_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(12, activation='sigmoid', name='final_au', kernel_initializer='glorot_normal'))\n",
    "    \n",
    "  # sigmoid classification for 12 au labels\n",
    "    model.compile(optimizer='adam', loss=loss_an, metrics=[subset_accuracy])\n",
    "    return model\n",
    "# create model end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d462267e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Path</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>AU1</th>\n",
       "      <th>AU2</th>\n",
       "      <th>AU4</th>\n",
       "      <th>AU5</th>\n",
       "      <th>AU6</th>\n",
       "      <th>AU9</th>\n",
       "      <th>AU12</th>\n",
       "      <th>AU15</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SN001Y_AngerDescribed_TrailNo_1011.jpg</td>\n",
       "      <td>C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SN001Y_AngerDescribed_TrailNo_1012.jpg</td>\n",
       "      <td>C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SN001Y_AngerDescribed_TrailNo_1013.jpg</td>\n",
       "      <td>C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SN001Y_AngerDescribed_TrailNo_1014.jpg</td>\n",
       "      <td>C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SN001Y_AngerDescribed_TrailNo_1015.jpg</td>\n",
       "      <td>C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                Filename  \\\n",
       "0      0  SN001Y_AngerDescribed_TrailNo_1011.jpg   \n",
       "1      1  SN001Y_AngerDescribed_TrailNo_1012.jpg   \n",
       "2      2  SN001Y_AngerDescribed_TrailNo_1013.jpg   \n",
       "3      3  SN001Y_AngerDescribed_TrailNo_1014.jpg   \n",
       "4      4  SN001Y_AngerDescribed_TrailNo_1015.jpg   \n",
       "\n",
       "                                                Path Emotion  AU1  AU2  AU4  \\\n",
       "0  C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...   anger    0    0    1   \n",
       "1  C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...   anger    0    0    2   \n",
       "2  C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...   anger    0    0    3   \n",
       "3  C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...   anger    0    0    4   \n",
       "4  C:\\Users\\user\\Documents\\MSc Computer\\EmotionDe...   anger    0    0    4   \n",
       "\n",
       "   AU5  AU6  AU9  AU12  AU15  AU17  AU20  AU25  AU26  \n",
       "0    0    0    0     0     0     0     0     0     0  \n",
       "1    0    0    0     0     0     0     0     0     0  \n",
       "2    0    0    0     0     0     0     0     0     0  \n",
       "3    0    0    0     0     0     0     0     0     0  \n",
       "4    0    0    0     0     0     0     0     0     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load disfa+ dataset\n",
    "disfa_df = pd.read_csv('AU_image_data.csv')\n",
    "disfa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "756252ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 950/950 [00:04<00:00, 204.71it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_df = disfa_df.sample(n=950)\n",
    "X,y = create_dataset(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd0f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model \n",
    "# create AU model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddadb3e",
   "metadata": {},
   "source": [
    "Train model using mini-batch gradient with a custom training loop.\n",
    "\n",
    "Need optimizer, loss function, and a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6bc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate an optimizer\n",
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "# instantiate a loss function\n",
    "# Prepare the metrics\n",
    "train_acc_metric = tensorflow.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tensorflow.keras.metrics.SparseCategoricalAccuracy()\n",
    "# prepare training dataset\n",
    "batch_size = 32\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cdf34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training dataset\n",
    "train_dataset = tensorflow.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# prepare the validation dataset\n",
    "val_dataset = tensorflow.data.Dataset.from_tensor_slices((X_val,y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3287dc",
   "metadata": {},
   "source": [
    "Here's our training loop:\n",
    "\n",
    "* We open a for loop that iterates over epochs\n",
    "* For each epoch, we open a for loop that iterates over the dataset, in batches\n",
    "* For each batch, we open a GradientTape() scope\n",
    "* Inside this scope, we call the model (forward pass) and compute the loss\n",
    "* Outside the scope, we retrieve the gradients of the weights of the model with regard to the loss\n",
    "* Finally, we use the optimizer to update the weights of the model based on the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0a7da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Start of epoch 0\n",
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(1.1142037, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 1.3638728e-02,  1.2928383e-02,  2.4042102e-03, ...,\n",
      "        -3.0311642e-03, -1.5525231e-02, -2.5319573e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 7.0203596e-04,  7.2361692e-04,  7.0102245e-04, ...,\n",
      "         5.5721775e-05,  2.4313033e-05, -2.2162716e-03],\n",
      "       ...,\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.0784370e-02,  2.5495784e-02,  2.6190763e-02, ...,\n",
      "        -4.2033946e-04, -3.8626097e-02, -2.0902824e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([ 0.03730034,  0.02445343,  0.03555912, -0.00672579, -0.02787081,\n",
      "       -0.0221787 , -0.03169718, -0.00189789, -0.00457014, -0.00211093,\n",
      "       -0.07597106, -0.04067653], dtype=float32)>]\n",
      "Training loss (for one batch) at step 0: 1.114203691482544\n",
      "Seen so far: 32\n",
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(0.9619689, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 7.8453049e-03,  4.8247082e-03,  9.6288538e-03, ...,\n",
      "        -5.4814829e-03, -1.6852034e-03, -6.1038870e-04],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       ...,\n",
      "       [-4.4234860e-04, -9.1477661e-05,  4.5225534e-05, ...,\n",
      "         9.6944677e-07, -6.2929164e-04, -6.6675368e-04],\n",
      "       [ 2.5221851e-02,  2.8255792e-02,  1.7503023e-02, ...,\n",
      "        -9.2004612e-03, -2.5324961e-02, -1.4639045e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([ 2.7251320e-02,  4.6149243e-02,  6.8978863e-03,  2.7286733e-02,\n",
      "       -2.6751457e-02, -1.2547300e-02, -3.9510392e-02,  4.8559614e-05,\n",
      "       -5.1455367e-03, -1.5384170e-02, -5.0673831e-02, -2.8285021e-02],\n",
      "      dtype=float32)>]\n",
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(1.0836637, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 1.3278948e-02,  5.4632146e-03, -5.5829245e-03, ...,\n",
      "         1.6109248e-05,  9.1451593e-04, -2.3361542e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.2841837e-03,  1.0236880e-03,  8.3731709e-04, ...,\n",
      "         3.2180374e-06,  1.0739724e-03,  6.8892154e-04],\n",
      "       ...,\n",
      "       [-1.8462841e-04, -2.0575518e-04,  4.6718164e-05, ...,\n",
      "         1.0177723e-07,  4.0709085e-05,  1.1086400e-05],\n",
      "       [ 2.5746796e-02,  9.4650676e-03, -2.4030883e-02, ...,\n",
      "        -8.1882263e-03,  1.4011342e-02,  9.2001772e-04],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([ 0.03957161,  0.01810775, -0.03803532,  0.03558762, -0.02502179,\n",
      "       -0.03596263,  0.02843426, -0.00780648, -0.02862849, -0.01031908,\n",
      "        0.02073691,  0.00229714], dtype=float32)>]\n",
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(0.59399456, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 5.0944015e-03, -7.1160517e-05,  4.2226622e-03, ...,\n",
      "         1.1436382e-05,  3.5253768e-03,  3.0750446e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.0168524e-03,  6.2960153e-04,  8.5183338e-04, ...,\n",
      "         4.0975319e-06,  1.1284854e-03,  1.0312306e-03],\n",
      "       ...,\n",
      "       [-7.3795626e-04, -9.0362947e-04,  1.7181509e-04, ...,\n",
      "         4.1787803e-07, -1.2460111e-03, -1.3092048e-03],\n",
      "       [ 1.1841837e-02, -1.0498574e-02,  4.7475956e-03, ...,\n",
      "         6.1565035e-05,  1.9597705e-02,  1.4748089e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([ 1.8848252e-02, -1.7746529e-02, -3.9314805e-03,  2.5336744e-02,\n",
      "       -4.1529592e-03, -3.4698926e-02,  5.2252065e-02,  2.4333899e-06,\n",
      "        3.9125749e-05,  1.1357296e-04,  2.3196209e-02,  1.7239638e-02],\n",
      "      dtype=float32)>]\n",
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(0.51694536, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[-1.96302179e-04, -1.67267909e-03,  5.64821996e-03, ...,\n",
      "        -1.66400138e-03,  3.58202728e-03,  2.46537477e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.23541448e-02, -1.37437368e-02,  5.08225756e-03, ...,\n",
      "         2.64357786e-05, -9.21139028e-03, -4.09753062e-03],\n",
      "       ...,\n",
      "       [ 2.13398580e-05,  3.46812453e-06,  1.38784380e-04, ...,\n",
      "        -3.28321214e-04,  1.60124735e-04,  1.15692455e-04],\n",
      "       [-1.70998536e-02, -2.20468119e-02,  1.28570097e-02, ...,\n",
      "        -8.93602893e-03,  5.93908224e-03,  9.88756865e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-0.04435756, -0.05116063,  0.01085447, -0.02082238, -0.0171146 ,\n",
      "       -0.01206847, -0.03374718, -0.01301964, -0.01814395, -0.02066459,\n",
      "       -0.00400097,  0.00391577], dtype=float32)>]\n",
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(0.8272187, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[-1.3951217e-02, -1.5186163e-02,  6.7187166e-03, ...,\n",
      "        -6.6210455e-03,  6.9633471e-03,  5.9579536e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       ...,\n",
      "       [ 2.1340773e-05,  5.8802966e-06,  2.1402180e-04, ...,\n",
      "         9.4292750e-07,  2.7588420e-04,  2.4374397e-04],\n",
      "       [-3.8278949e-02, -4.6108097e-02,  1.3922611e-02, ...,\n",
      "        -1.4633502e-02,  1.3241546e-02,  6.8674255e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-4.7351196e-02, -6.4965673e-02,  1.8746924e-02, -3.1384107e-02,\n",
      "        4.4981025e-02,  3.3702128e-02, -3.2367497e-03,  9.2488426e-07,\n",
      "       -2.3018220e-03, -2.5768077e-02,  2.3457533e-02,  2.0797290e-02],\n",
      "      dtype=float32)>]\n",
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(1.1760088, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[-3.6990566e-03, -1.4782940e-03, -1.7339980e-03, ...,\n",
      "        -5.7622412e-04,  9.7625507e-03,  5.6410017e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.2170195e-03,  1.5737046e-03,  2.0622932e-03, ...,\n",
      "         1.3535253e-04, -7.3834402e-05,  2.5328503e-03],\n",
      "       ...,\n",
      "       [-4.1696546e-03, -1.9379364e-03,  7.3904626e-04, ...,\n",
      "         4.8940736e-05,  1.7225301e-03,  1.3750467e-03],\n",
      "       [-3.5149917e-02, -2.4727175e-02,  3.8950171e-03, ...,\n",
      "        -3.6938954e-03,  3.1364255e-02,  1.9611452e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-0.05671066, -0.03712289, -0.00239549, -0.04781579,  0.06081584,\n",
      "        0.04887977,  0.03011772, -0.01822777, -0.02732418, -0.00847736,\n",
      "        0.04386491,  0.02909813], dtype=float32)>]\n",
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(0.2727489, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 0.00017283, -0.00128908, -0.00388905, ..., -0.00115813,\n",
      "         0.00553725,  0.00049449],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 0.0007422 ,  0.00102123, -0.00448989, ...,  0.00026521,\n",
      "        -0.00392946, -0.00441468],\n",
      "       [ 0.00308051,  0.00336085, -0.01203934, ..., -0.00849143,\n",
      "         0.01441346,  0.00118768],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([ 0.01036699,  0.01168087, -0.0184905 , -0.01081737, -0.0046781 ,\n",
      "       -0.01825439, -0.01624541, -0.00781006, -0.02508269, -0.0170835 ,\n",
      "        0.0129963 ,  0.00518869], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 12)\n",
      "(32, 12)\n",
      "tf.Tensor(0.2558704, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss_value)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Use the gradient tape to automatically retrieve\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# the gradients of the trainable variables with respect to the loss.\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(grads)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Run one step of gradient descent by updating\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# the value of the variables to minimize the loss.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:577\u001b[0m, in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    568\u001b[0m shape_0, shape_1 \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape_n([op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# in Eager mode.\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 577\u001b[0m     \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_backprop_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    587\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d_backprop_filter(\n\u001b[0;32m    588\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    589\u001b[0m         shape_1,\n\u001b[0;32m    590\u001b[0m         grad,\n\u001b[0;32m    591\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[0;32m    592\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[0;32m    593\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    594\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[0;32m    595\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[0;32m    596\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format)\n\u001b[0;32m    597\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1239\u001b[0m, in \u001b[0;36mconv2d_backprop_input\u001b[1;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   1238\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1239\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv2DBackpropInput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_backprop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_cudnn_on_gpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpadding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplicit_paddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdilations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   1245\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define number of epochs\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\n Start of epoch {epoch}')\n",
    "    \n",
    "    # iterate over the batches of the dataset\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation\n",
    "        \n",
    "        with tensorflow.GradientTape() as tape:\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are foing to be recorded \n",
    "            # on the GradientTape\n",
    "            logits = model(x_batch_train, training=True) # logits of the minibatch\n",
    "            print(y_batch_train.shape)\n",
    "            print(logits.shape)\n",
    "            # compute the loss value for this minibatch\n",
    "            loss_value = loss_an(y_batch_train, logits)\n",
    "            print(loss_value)\n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        print(grads)\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Log every 200 batches\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "            f'Training loss (for one batch) at step {step}: {float(loss_value)}')\n",
    "            print(f'Seen so far: {(step+1)*batch_size}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c65c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = np.array([0,1,1,0,0,1,1,0,1,0])\n",
    "lt_new = (lt==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dcd304b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True,  True, False, False,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e698dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array2 = np.zeros((12, 12), int)\n",
    "np_array = np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46d876f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bebd46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array2[1][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dffcf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0,11,(12,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c98a4bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 10],\n",
       "       [ 6,  6],\n",
       "       [ 9,  2],\n",
       "       [ 7,  3],\n",
       "       [ 9,  0],\n",
       "       [ 4,  2],\n",
       "       [ 6,  1],\n",
       "       [ 2,  6],\n",
       "       [ 4, 10],\n",
       "       [ 1,  0],\n",
       "       [ 1,  6],\n",
       "       [ 0,  9]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02b18257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0],\n",
       "       [3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_in = tuple(zip(*indices))\n",
    "np_array2[new_in] = 3\n",
    "np_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e37fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
