{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646783d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Needed\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any, List, Tuple, Union\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "import tensorflow\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4691b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset start\n",
    "def create_dataset(df):\n",
    "    X_dataset = []\n",
    "    img_list = df['Path'].tolist()\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        \n",
    "        img = image.load_img(img_list[i])\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255.\n",
    "        X_dataset.append(img)\n",
    "\n",
    "    X = np.array(X_dataset)\n",
    "  # drop unnecessary columns not used for training\n",
    "    y = np.array(df.drop(['Index', 'Filename','Path','Emotion'], axis=1))\n",
    "\n",
    "    return X, y\n",
    "# create dataset end\n",
    "def label_binarizer(y_intensity,threshold_val):\n",
    "    return np.where(y_intensity<threshold_val, 0, 1)\n",
    "def subset_accuracy(y_true,y_pred):\n",
    "#     y_true = tensorflow.py_function(label_binarizer,(y_true,0.5), tensorflow.double)\n",
    "#     y_pred = tensorflow.py_function(label_binarizer,(y_pred,0.5), tensorflow.double)\n",
    "    return tensorflow.py_function(accuracy_score,(y_true,y_pred),tensorflow.double)\n",
    "\n",
    "def load_model_data(model_path, opt_path):\n",
    "    model = load_model(model_path,custom_objects={\"subset_accuracy\":subset_accuracy})\n",
    "    return model\n",
    "# define Assume Negative loss\n",
    "# def loss_an(y_pred, y_true):\n",
    "#     bce_loss = tensorflow.keras.losses.BinaryCrossentropy()\n",
    "#     return bce_loss(y_pred,y_true)\n",
    "\n",
    "# create model start\n",
    "def create_model(width=224, height=224):\n",
    "  # load pretrained model 'VGG16'\n",
    "    base_model = keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(width, height, 3))\n",
    "    base_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(12, activation='sigmoid', name='final_au', kernel_initializer='glorot_normal'))\n",
    "    return model\n",
    "# create model end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a45cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_an(logits, noisy_labels, P):\n",
    "    \"\"\"\n",
    "    This function calculates the loss matrix of assumed negative labels and \n",
    "    the corrected negative loss matrix.\n",
    "    Args:\n",
    "        logits(tensor): keras model predictions - tensor\n",
    "        noisy_labels(numpy.ndarray): label vector - numpy.ndarray\n",
    "        P (dict): parameter dictionary\n",
    "        \n",
    "    Returns:\n",
    "        loss_matirx, corrected loss matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    # initialize KerasBinaryCrossentropy loss\n",
    "    BCE = tensorflow.keras.losses.BinaryCrossentropy(\n",
    "#     from_logits = True,\n",
    "    reduction = \"none\"\n",
    "    )\n",
    "    # compute assumed negative loss binary cross entropy matrix\n",
    "    loss_matrix = BCE(noisy_labels,logits)\n",
    "#     print(f'first loss matrix.shape from first definition of loss_an: {loss_matrix.shape}')\n",
    "    \n",
    "    # change noisy labels to boolean vector\n",
    "    noisy_labels = (noisy_labels>0.5)\n",
    "    # compute logical not of noisy labels boolean vector\n",
    "    noisy_labels = tensorflow.logical_not(noisy_labels)\n",
    "    # change boolean tensor to binary tensor\n",
    "    noisy_labels = tensorflow.where(noisy_labels, 1, 0)\n",
    "    # change noisy labels to float32 dtype\n",
    "    noisy_labels = tensorflow.cast(noisy_labels, dtype=tensorflow.float32)\n",
    "    # calculate corrected loss matrix\n",
    "    corrected_loss_matrix = BCE(noisy_labels,logits)\n",
    "    return loss_matrix, corrected_loss_matrix\n",
    "\n",
    "def compute_batch_loss(logits, noisy_labels, P):\n",
    "    # get batch size\n",
    "    batch_size = int(logits.shape[0])\n",
    "    # get num classes in multilabel problem\n",
    "    num_classes = int(logits.shape[1])\n",
    "    # get boolean matrix for all the labels equal to\n",
    "    unobserved_mask = (noisy_labels == 0) # 32 * 12\n",
    "    # calculate batch loss and corrected loss matrices\n",
    "    loss_matrix, corrected_loss_matrix = loss_an(logits, noisy_labels, P)\n",
    "    correction_indices = None\n",
    "\n",
    "    if P['clean_rate'] == 1: # epoch ==1\n",
    "        final_loss_matrix = loss_matrix\n",
    "    # after the first epoch\n",
    "    else:\n",
    "        if P['mod_scheme'] == 'LL-Cp':\n",
    "            k = tensorflow.math.ceil(batch_size * num_classes * P['delta_rel'])\n",
    "        else:\n",
    "            k = tensorflow.math.ceil(batch_size * num_classes * (1 - P['clean_rate']))\n",
    "            \n",
    "        unobserved_mask = tensorflow.where(unobserved_mask,1,0) # 32 * 12\n",
    "        \n",
    "        unobserved_mask = tensorflow.cast(unobserved_mask, dtype = tensorflow.float32)\n",
    "#         # convert loss matrix to ndarray for multiplication\n",
    "#         # change k to int32 which is reuqeired\n",
    "#         k = tensorflow.cast(k, dtype = tensorflow.int32)\n",
    "#         print(k)\n",
    "\n",
    "#         print(unobserved_mask)\n",
    "#         print(loss_matrix)\n",
    "    \n",
    "        unobserved_loss = tensorflow.math.multiply( unobserved_mask, loss_matrix.numpy().reshape([batch_size,-1]))#.numpy().reshape([32,-1])\n",
    "# #         print(unobserved_loss.shape)\n",
    "        flatten_unobserved_loss = tensorflow.reshape(unobserved_loss, [-1])\n",
    "# #         print(flatten_unobserved_loss)\n",
    "        topk = tensorflow.math.top_k(flatten_unobserved_loss, tensorflow.cast(k,dtype = tensorflow.int32))\n",
    "        topk_lossvalue = topk.values[-1]\n",
    "        \n",
    "        correction_indices = tensorflow.where(unobserved_loss > topk_lossvalue)\n",
    "        \n",
    "        if P['mod_scheme'] in ['LL-Ct','LL-Cp']:\n",
    "#             cond = tensorflow.less(unobserved_loss, topk_lossvalue)\n",
    "#             final_loss_matrix = tensorflow.where(cond, tensorflow.where(cond,unobserved_loss,topk_lossvalue),\n",
    "#                                                 tensorflow.where(cond, topk_lossvalue, unobserved_loss))\n",
    "#             print(tensorflow.less(unobserved_loss < topk_lossvalue))\n",
    "#             print(loss_matrix.numpy().reshape([batch_size,-1]))\n",
    "            final_loss_matrix = tensorflow.where(unobserved_loss < topk_lossvalue, loss_matrix.numpy().reshape([batch_size,-1]), corrected_loss_matrix.numpy().reshape([batch_size,-1]))\n",
    "#             print(final_loss_matrix)\n",
    "        else:\n",
    "            zero_loss_matrix = tensorflow.zeros_like(loss_matrix)\n",
    "            final_loss_matrix = tensorflow.where(unobserved_loss < topk_lossvalue, loss_matrix, zero_loss_matrix)\n",
    "    main_loss = tensorflow.math.reduce_mean(final_loss_matrix)\n",
    "\n",
    "    return main_loss, correction_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36cffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 950/950 [00:08<00:00, 113.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# load disfa+ dataset\n",
    "disfa_df = pd.read_csv('AU_image_data.csv')\n",
    "disfa_df.head()\n",
    "sample_df = disfa_df.sample(n=950)\n",
    "X,y = create_dataset(sample_df)\n",
    "y = np.where(y>=3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8978b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model \n",
    "# create AU model\n",
    "model = create_model()\n",
    "# hyperparameter dictionary\n",
    "P = {\n",
    "    \"num_epochs\": 3,\n",
    "    \"lr\" : 1e-3,\n",
    "    \"optimizer\" :\"adam\",\n",
    "    \"num_epochs\" : 20,\n",
    "    \"clean_rate\": 1,\n",
    "    \"delta_rel\": 0.1,\n",
    "    \"mod_scheme\": \"LL-Cp\"\n",
    "}\n",
    "# instantiate an optimizer\n",
    "if P['optimizer'] == 'adam':\n",
    "    opt = tensorflow.keras.optimizers.Adam(learning_rate=P['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c33a516f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LL-Cp'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P['mod_scheme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e116ae52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.optimizer_v2.adam.Adam at 0x1a5ef1845e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d82e085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, batch sizem, and initial learning rate\n",
    "\n",
    "# prepare training dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10f31fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5e877a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 0: make prediction 0:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 4.7467030e-03,  6.8172282e-03,  5.7903938e-03, ...,\n",
      "         1.3122389e-02,  9.2135360e-03,  1.0020803e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.4194992e-06,  1.6064603e-03,  1.5711115e-03, ...,\n",
      "         1.2874155e-03,  2.3118667e-03,  1.8747831e-03],\n",
      "       ...,\n",
      "       [ 5.4082461e-04,  8.5003226e-04,  8.5837633e-04, ...,\n",
      "         1.2254197e-03,  1.1141689e-03,  9.0724666e-04],\n",
      "       [ 1.4482306e-02,  2.6461679e-02,  2.1326790e-02, ...,\n",
      "         4.4542298e-02,  3.5432111e-02,  3.5034962e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([0.02329276, 0.0408919 , 0.03170271, 0.03918242, 0.01262129,\n",
      "       0.03365639, 0.03725169, 0.05323652, 0.02002733, 0.06549368,\n",
      "       0.05370881, 0.05200002], dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 1:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[-6.7129481e-04, -5.4407178e-04, -2.4179737e-03, ...,\n",
      "         8.2538632e-04, -9.3161431e-04, -9.8876050e-04],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.7896851e-05,  7.0562768e-05, -1.3718257e-03, ...,\n",
      "         2.3922068e-04, -5.8241520e-04,  9.4374336e-05],\n",
      "       ...,\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.1261541e-03, -3.8260643e-03, -1.2238013e-02, ...,\n",
      "         3.1562999e-03, -4.5451643e-03, -2.1853074e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-0.00748607, -0.00499211, -0.01693748, -0.00277541, -0.00568131,\n",
      "        0.00128046, -0.00881525,  0.00210925, -0.00155792,  0.00534979,\n",
      "       -0.00703044, -0.00207325], dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 2:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 2.2634109e-05,  1.5415511e-05, -8.3330384e-04, ...,\n",
      "         4.4190954e-05, -2.5651092e-03, -5.4375792e-04],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.1997788e-04, -5.2038667e-04,  6.0014190e-06, ...,\n",
      "         2.6700038e-06,  3.8098426e-06,  1.4211831e-06],\n",
      "       ...,\n",
      "       [ 4.4291812e-07,  4.2762659e-07, -8.3966421e-05, ...,\n",
      "         9.4300628e-07,  1.0241430e-06,  3.9785166e-07],\n",
      "       [-1.4430990e-03, -1.4695786e-03, -6.4200293e-03, ...,\n",
      "        -1.0929198e-03, -8.8972384e-03, -6.5264804e-04],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-0.00402173, -0.0040618 , -0.01190424, -0.00614825, -0.01024464,\n",
      "       -0.00618188, -0.01020037, -0.00197371, -0.00412876, -0.0018362 ,\n",
      "       -0.0163664 , -0.00193424], dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 3:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[-5.2476110e-04, -5.2855827e-04, -1.4612549e-03, ...,\n",
      "         3.0954573e-06, -2.9390256e-03, -6.0969155e-04],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 6.5995982e-07,  1.2047475e-07,  3.6521412e-06, ...,\n",
      "         1.2260075e-07, -5.2652630e-04,  1.4550835e-07],\n",
      "       ...,\n",
      "       [-1.5428916e-04, -1.5438309e-04,  2.9678476e-06, ...,\n",
      "         6.0697239e-08, -2.6478703e-04, -2.6512658e-04],\n",
      "       [-7.0133279e-03, -6.3591832e-03, -6.0426560e-03, ...,\n",
      "         1.2604543e-05, -1.5310006e-02, -5.1766904e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-1.0353522e-02, -8.3155483e-03, -9.7650448e-03, -1.0397967e-02,\n",
      "       -1.2130751e-02, -4.1566361e-03, -1.4491358e-02, -2.0732628e-03,\n",
      "       -2.0743376e-03,  2.1667645e-05, -2.6967874e-02, -8.3149718e-03],\n",
      "      dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 4:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[-2.1052423e-03, -7.6030940e-04, -7.6362962e-04, ...,\n",
      "         6.3876342e-07, -2.4291785e-03, -7.6068047e-04],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.0547646e-03, -1.0606988e-03,  3.5954665e-05, ...,\n",
      "         1.2901964e-07, -6.0653292e-05,  1.5887566e-07],\n",
      "       ...,\n",
      "       [-4.3249544e-04, -4.3305213e-04,  1.6524509e-05, ...,\n",
      "         4.7835563e-08, -2.3182140e-04, -2.3374622e-04],\n",
      "       [-9.7529963e-03, -9.3588755e-03, -4.4839922e-03, ...,\n",
      "        -8.7546784e-04, -8.0824774e-03, -4.2747478e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-0.01863759, -0.01873933, -0.00695552, -0.01456916, -0.0022884 ,\n",
      "       -0.00207829, -0.00819183, -0.00208071, -0.00416168, -0.00207929,\n",
      "       -0.01442193, -0.00832684], dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 5:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[-9.8501460e-04, -1.0238879e-03, -2.9520714e-03, ...,\n",
      "         1.4655812e-07, -1.1494657e-03,  4.6296290e-07],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.4867431e-03,  3.5946937e-07, -1.4428212e-03, ...,\n",
      "         1.3232302e-08,  6.1147011e-06,  4.1212765e-08],\n",
      "       ...,\n",
      "       [-3.0940564e-04, -3.1244764e-04,  3.1915795e-05, ...,\n",
      "         8.8984358e-09, -2.7551202e-04, -2.8041576e-04],\n",
      "       [-3.9893463e-03, -4.1025849e-03, -6.2363185e-03, ...,\n",
      "         4.7477496e-07, -5.1080687e-03, -4.3240543e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-7.9992134e-03, -8.3205597e-03, -7.4350270e-03, -8.3181150e-03,\n",
      "        5.2253199e-03, -6.2481118e-03, -1.8245315e-03,  5.7317584e-07,\n",
      "       -2.0797851e-03,  8.8396581e-07, -5.8815759e-03, -4.1637523e-03],\n",
      "      dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 6:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 1.2425828e-04,  1.8728590e-06,  7.6557399e-06, ...,\n",
      "        -4.7843863e-05, -4.7926333e-05, -8.3878491e-05],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.0694124e-04,  1.8478878e-06,  3.0591895e-04, ...,\n",
      "         6.4942367e-09,  2.9676336e-05,  5.1524673e-08],\n",
      "       ...,\n",
      "       [ 1.6181250e-05,  3.5646755e-07,  1.7149965e-05, ...,\n",
      "         2.1761670e-09, -3.0317589e-05, -4.0863892e-05],\n",
      "       [-1.1188912e-03, -2.3396702e-03, -3.0914634e-03, ...,\n",
      "        -2.7190256e-03, -5.7413387e-03, -6.2718350e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-2.2542374e-03, -4.1414206e-03, -3.3612414e-03, -6.2144287e-03,\n",
      "        1.5006805e-02, -2.0812338e-03, -5.7195695e-03,  2.5398398e-07,\n",
      "       -2.0797630e-03, -4.1664001e-03, -7.3160939e-03, -8.3306618e-03],\n",
      "      dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 7:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[-2.5026864e-04, -1.5325974e-03,  1.9478691e-03, ...,\n",
      "         6.9202342e-09, -9.9654379e-04, -6.8509352e-04],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.2607327e-04,  3.7159245e-06,  6.8907026e-04, ...,\n",
      "        -1.2847768e-03, -2.7877989e-04,  8.9070447e-08],\n",
      "       ...,\n",
      "       [ 5.0370509e-05,  4.3309427e-07,  6.6373221e-05, ...,\n",
      "         5.9636429e-10, -3.2846778e-04, -2.0222513e-04],\n",
      "       [-5.7371692e-03, -1.1061391e-02,  9.7510619e-03, ...,\n",
      "        -6.7095854e-04, -1.1591343e-02, -1.0108655e-02],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([-6.7065298e-03, -1.2447780e-02,  1.4998694e-02, -8.2512982e-03,\n",
      "        1.1596913e-02, -2.0817120e-03, -2.9362717e-03, -2.0832503e-03,\n",
      "        4.4143153e-06, -2.0832359e-03, -1.3573082e-02, -1.2497221e-02],\n",
      "      dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 8:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 4.00482118e-03,  1.68567694e-05,  2.15407368e-03, ...,\n",
      "        -6.43587962e-04,  2.54727900e-04, -3.73617018e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.88673876e-04,  8.95114340e-07,  1.34601229e-04, ...,\n",
      "         2.26732438e-10,  2.95867067e-05,  1.44999825e-08],\n",
      "       ...,\n",
      "       [ 1.90605101e-06,  1.22080106e-08,  5.29161844e-06, ...,\n",
      "         4.17662346e-12,  6.62545801e-07,  4.22371166e-10],\n",
      "       [ 1.30980182e-02, -1.81474537e-03,  7.85853155e-03, ...,\n",
      "        -1.38036872e-03, -6.82072248e-04, -2.00001500e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([ 2.2990843e-02, -4.0366836e-03,  1.3252810e-02, -3.9241123e-03,\n",
      "       -1.7627815e-03, -4.1647218e-03, -7.3726461e-03,  4.2829861e-08,\n",
      "       -2.0778137e-03, -2.0832885e-03, -9.3195576e-04, -2.0795634e-03],\n",
      "      dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 9:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 3.7038729e-03, -9.0373453e-04,  1.0084484e-03, ...,\n",
      "        -6.9581269e-04,  3.1346541e-03,  1.3676395e-06],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 7.6804723e-04,  1.0525269e-05,  3.0806183e-04, ...,\n",
      "         2.4617258e-10,  3.0091286e-04,  4.6364015e-08],\n",
      "       ...,\n",
      "       [ 5.6535584e-05,  1.6127536e-06,  1.6129738e-05, ...,\n",
      "         3.7358200e-11, -9.2277951e-05,  1.7357424e-08],\n",
      "       [ 1.2865051e-02, -3.8641789e-03,  5.8042053e-03, ...,\n",
      "        -1.2398898e-03,  7.0445556e-03, -1.5786010e-03],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([ 2.1768980e-02, -3.6108333e-03,  8.2189934e-03, -1.1606770e-02,\n",
      "       -3.8952311e-03, -4.1611725e-03, -3.9676633e-03,  2.7101032e-07,\n",
      "       -6.2328177e-03, -2.0830198e-03,  1.3210156e-02, -2.0703736e-03],\n",
      "      dtype=float32)>]\n",
      "\n",
      " Epoch 0: make prediction 10:\n",
      "None\n",
      "[<tf.Tensor: shape=(25088, 12), dtype=float32, numpy=\n",
      "array([[ 1.94950856e-03,  1.58108101e-04,  5.71237579e-05, ...,\n",
      "         1.01151498e-09,  4.21401486e-03, -3.85795400e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [ 2.12088096e-04,  1.89290076e-05,  1.65144316e-04, ...,\n",
      "         1.52381011e-10,  3.04504210e-04,  7.74043514e-08],\n",
      "       ...,\n",
      "       [ 1.13661830e-04,  9.67296364e-06,  1.08714325e-04, ...,\n",
      "         6.50956997e-11, -2.96283997e-05, -2.62675283e-04],\n",
      "       [ 8.06529168e-03, -4.08234540e-03,  4.38366504e-03, ...,\n",
      "         6.74138922e-09,  1.19308792e-02, -6.14120066e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)>, <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([ 1.44314244e-02, -8.27278662e-03,  7.57607957e-03, -9.60513670e-03,\n",
      "       -2.47784541e-03,  3.08942117e-06,  1.24375755e-02,  8.59623306e-09,\n",
      "        2.19917711e-05,  1.14582939e-08,  2.24878453e-02, -1.04004098e-02],\n",
      "      dtype=float32)>]\n",
      "tf.Tensor(0.6, shape=(), dtype=float64)\n",
      "saving model weight for best metric 0.6\n",
      "\n",
      " Epoch 1: make prediction 0:\n",
      "tf.Tensor(\n",
      "[[ 4  0]\n",
      " [ 4  1]\n",
      " [ 4  3]\n",
      " [ 4  6]\n",
      " [ 4  7]\n",
      " [ 4  8]\n",
      " [ 4  9]\n",
      " [ 4 11]\n",
      " [13  0]\n",
      " [13  1]\n",
      " [13  3]\n",
      " [13  6]\n",
      " [13  7]\n",
      " [13  9]\n",
      " [13 10]\n",
      " [13 11]\n",
      " [17  0]\n",
      " [17  1]\n",
      " [17  3]\n",
      " [17  6]\n",
      " [17  7]\n",
      " [17  9]\n",
      " [17 10]\n",
      " [17 11]\n",
      " [18  0]\n",
      " [18  1]\n",
      " [18  2]\n",
      " [18  3]\n",
      " [18  4]\n",
      " [18  6]\n",
      " [18  7]\n",
      " [18  8]\n",
      " [18  9]\n",
      " [18 11]\n",
      " [19  1]\n",
      " [19  2]\n",
      " [19  3]\n",
      " [19  4]\n",
      " [19  5]\n",
      " [19  7]\n",
      " [19  8]\n",
      " [19 10]\n",
      " [19 11]], shape=(43, 2), dtype=int64)\n",
      "[None, None]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['final_au/kernel:0', 'final_au/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'final_au/kernel:0' shape=(25088, 12) dtype=float32, numpy=\narray([[ 8.29929486e-03,  2.05741357e-03,  8.00175767e-04, ...,\n        -2.29696985e-02,  1.16526440e-03,  1.22488765e-02],\n       [-1.07839964e-02,  7.96775625e-04,  2.03310256e-03, ...,\n         7.02012982e-03, -7.24897394e-03, -1.04308203e-02],\n       [ 9.64653492e-03, -2.18940880e-02, -6.99603837e-03, ...,\n        -3.13332514e-03, -4.43929061e-03, -1.19671514e-02],\n       ...,\n       [ 1.79589633e-02,  7.91123696e-03,  2.50317459e-03, ...,\n        -1.79166673e-05,  7.69816991e-03, -2.15028878e-02],\n       [-1.51878444e-03, -1.38948467e-02,  4.95119020e-03, ...,\n        -7.77135743e-03, -1.17168725e-02, -1.26415165e-02],\n       [ 5.87868458e-03,  9.47025232e-03,  7.10674049e-03, ...,\n         5.18451736e-04, -1.01820566e-02,  2.01056362e-03]], dtype=float32)>), (None, <tf.Variable 'final_au/bias:0' shape=(12,) dtype=float32, numpy=\narray([-0.00034852, -0.0005311 , -0.00061084, -0.00039694, -0.00078524,\n       -0.00240677, -0.00028599, -0.00408829, -0.00167799, -0.004216  ,\n       -0.00039077, -0.00210849], dtype=float32)>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(grads)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m P[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmod_scheme\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLL-Cp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m correction_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# change batch values\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     y[correction_indices[:,\u001b[38;5;241m0\u001b[39m],correction_indices[:,\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:640\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    600\u001b[0m                     grads_and_vars,\n\u001b[0;32m    601\u001b[0m                     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    602\u001b[0m                     experimental_aggregate_gradients\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    603\u001b[0m   \u001b[38;5;124;03m\"\"\"Apply gradients to variables.\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \n\u001b[0;32m    605\u001b[0m \u001b[38;5;124;03m  This is the second part of `minimize()`. It returns an `Operation` that\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    RuntimeError: If called in a cross-replica context.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 640\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_empty_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m   var_list \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m (_, v) \u001b[38;5;129;01min\u001b[39;00m grads_and_vars]\n\u001b[0;32m    643\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name):\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;66;03m# Create iteration if necessary.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\utils.py:73\u001b[0m, in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered:\n\u001b[0;32m     72\u001b[0m   variable \u001b[38;5;241m=\u001b[39m ([v\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m _, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars],)\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided `grads_and_vars` is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrads_and_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vars_with_empty_grads:\n\u001b[0;32m     76\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m     77\u001b[0m       (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradients do not exist for variables \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m when minimizing the loss. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre using `model.compile()`, did you forget to provide a `loss`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument?\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     80\u001b[0m       ([v\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vars_with_empty_grads]))\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: (['final_au/kernel:0', 'final_au/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'final_au/kernel:0' shape=(25088, 12) dtype=float32, numpy=\narray([[ 8.29929486e-03,  2.05741357e-03,  8.00175767e-04, ...,\n        -2.29696985e-02,  1.16526440e-03,  1.22488765e-02],\n       [-1.07839964e-02,  7.96775625e-04,  2.03310256e-03, ...,\n         7.02012982e-03, -7.24897394e-03, -1.04308203e-02],\n       [ 9.64653492e-03, -2.18940880e-02, -6.99603837e-03, ...,\n        -3.13332514e-03, -4.43929061e-03, -1.19671514e-02],\n       ...,\n       [ 1.79589633e-02,  7.91123696e-03,  2.50317459e-03, ...,\n        -1.79166673e-05,  7.69816991e-03, -2.15028878e-02],\n       [-1.51878444e-03, -1.38948467e-02,  4.95119020e-03, ...,\n        -7.77135743e-03, -1.17168725e-02, -1.26415165e-02],\n       [ 5.87868458e-03,  9.47025232e-03,  7.10674049e-03, ...,\n         5.18451736e-04, -1.01820566e-02,  2.01056362e-03]], dtype=float32)>), (None, <tf.Variable 'final_au/bias:0' shape=(12,) dtype=float32, numpy=\narray([-0.00034852, -0.0005311 , -0.00061084, -0.00039694, -0.00078524,\n       -0.00240677, -0.00028599, -0.00408829, -0.00167799, -0.004216  ,\n       -0.00039077, -0.00210849], dtype=float32)>))."
     ]
    }
   ],
   "source": [
    "# calculate the number of batch updates per epoch\n",
    "numUpdates = int(X_train.shape[0]/batch_size)\n",
    "# loop over the number of epochs\n",
    "for epoch in range(0, P['num_epochs']):\n",
    "    best_accuracy = 0\n",
    "    # loop over the data in batch size increments\n",
    "    for i in range(0, numUpdates):\n",
    "        # determine the start and end slice indexes for the current batch\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        # take a step\n",
    "#         print(model.trainable_weights)\n",
    "        with tensorflow.GradientTape() as tape:\n",
    "            # make prediction using the model and then calculate the loss\n",
    "            print(f'\\n Epoch {epoch}: make prediction {i}:')\n",
    "            x = X_train[start:end]\n",
    "            pred = model(x, training = True)\n",
    "#             print(pred)\n",
    "            # calculate the loss\n",
    "            y = y_train[start:end]\n",
    "            loss, correction_indices = compute_batch_loss(pred, y, P)\n",
    "            print(correction_indices)\n",
    "        # calculate gradients using our tape and then update the model weights\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        print(grads)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        if P['mod_scheme'] == \"LL-Cp\" and correction_indices is not None:\n",
    "            # change batch values\n",
    "            y[correction_indices[:,0],correction_indices[:,1]] = 1\n",
    "    # calculate metrics\n",
    "    y = tensorflow.cast(y, dtype=tensorflow.int32)\n",
    "    pred = tensorflow.cast(pred, dtype=tensorflow.int32)\n",
    "#     print(y)\n",
    "#     print(pred)\n",
    "    metrics = subset_accuracy(y, pred)\n",
    "    print(metrics)\n",
    "    if best_accuracy < metrics:\n",
    "        best_accuracy = metrics\n",
    "        best_accuracy_epoch = epoch\n",
    "        print(f'saving model weight for best metric {best_accuracy}')\n",
    "        os.path.join('C:\\\\Users\\\\user\\\\Documents\\\\MSc Computer\\\\EmotionDetectionUsingCNN\\\\MissingLabel',f'model-{epoch:02d}-{best_accuracy:.2f}.hdf5')\n",
    "#     print(metrics)\n",
    "    P['clean_rate'] -= P['delta_rel']\n",
    "#         steps(X_train[start:end], y_train[start:end], P)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a89349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_indices_np = correction_indices.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d46d274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0],\n",
       "       [ 4,  1],\n",
       "       [ 4,  3],\n",
       "       [ 4,  6],\n",
       "       [ 4,  7],\n",
       "       [ 4,  8],\n",
       "       [ 4,  9],\n",
       "       [ 4, 11],\n",
       "       [13,  0],\n",
       "       [13,  1],\n",
       "       [13,  3],\n",
       "       [13,  6],\n",
       "       [13,  7],\n",
       "       [13,  9],\n",
       "       [13, 10],\n",
       "       [13, 11],\n",
       "       [17,  0],\n",
       "       [17,  1],\n",
       "       [17,  3],\n",
       "       [17,  6],\n",
       "       [17,  7],\n",
       "       [17,  9],\n",
       "       [17, 10],\n",
       "       [17, 11],\n",
       "       [18,  0],\n",
       "       [18,  1],\n",
       "       [18,  2],\n",
       "       [18,  3],\n",
       "       [18,  4],\n",
       "       [18,  6],\n",
       "       [18,  7],\n",
       "       [18,  8],\n",
       "       [18,  9],\n",
       "       [18, 11],\n",
       "       [19,  1],\n",
       "       [19,  2],\n",
       "       [19,  3],\n",
       "       [19,  4],\n",
       "       [19,  5],\n",
       "       [19,  7],\n",
       "       [19,  8],\n",
       "       [19, 10],\n",
       "       [19, 11]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_indices_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4b8901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = correction_indices_np.shape[0]\n",
    "columns = correction_indices_np.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f87b2fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "7\n",
      "4\n",
      "8\n",
      "4\n",
      "9\n",
      "4\n",
      "11\n",
      "13\n",
      "0\n",
      "13\n",
      "1\n",
      "13\n",
      "3\n",
      "13\n",
      "6\n",
      "13\n",
      "7\n",
      "13\n",
      "9\n",
      "13\n",
      "10\n",
      "13\n",
      "11\n",
      "17\n",
      "0\n",
      "17\n",
      "1\n",
      "17\n",
      "3\n",
      "17\n",
      "6\n",
      "17\n",
      "7\n",
      "17\n",
      "9\n",
      "17\n",
      "10\n",
      "17\n",
      "11\n",
      "18\n",
      "0\n",
      "18\n",
      "1\n",
      "18\n",
      "2\n",
      "18\n",
      "3\n",
      "18\n",
      "4\n",
      "18\n",
      "6\n",
      "18\n",
      "7\n",
      "18\n",
      "8\n",
      "18\n",
      "9\n",
      "18\n",
      "11\n",
      "19\n",
      "1\n",
      "19\n",
      "2\n",
      "19\n",
      "3\n",
      "19\n",
      "4\n",
      "19\n",
      "5\n",
      "19\n",
      "7\n",
      "19\n",
      "8\n",
      "19\n",
      "10\n",
      "19\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for row in range(0,rows):\n",
    "    for column in range(0, columns):\n",
    "        if y[row][column] == 1:\n",
    "            y[row][column]= 0\n",
    "        else:\n",
    "            y[row][column] = 1\n",
    "\n",
    "        print(correction_indices_np[row][column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array2 = np.zeros((2, 3), int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d7bb0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize array with 0s\n",
    "x = np.zeros((32,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4227e0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "655b7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all the rows\n",
    "for i in range(len(x)):\n",
    "    rand_column_index = np.random.randint(0,11)\n",
    "    x[i][rand_column_index] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d99bbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_dataset(noisy_labels):\n",
    "    \n",
    "    for i in range(len(noisy_labels)):\n",
    "        rand_column_index = np.random.randint(0,11)\n",
    "        noisy_labels[i][rand_column_index]=1\n",
    "    return noisy_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2189e851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = partial_dataset(x)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb6d7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array2 = np.zeros((2, 3), int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eac9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array3 = np.ones((2,3),int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dc3557d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array2[0:2] = np_array3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "66952720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63696643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Assume Negative loss\n",
    "# def loss_an(y_pred, y_true):\n",
    "#     bce_loss = tensorflow.keras.losses.BinaryCrossentropy()\n",
    "#     return bce_loss(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e94824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = tensorflow.keras.losses.BinaryCrossentropy(from_logits=False, reduction=tensorflow.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f7f256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0, 1], [0, 0]])\n",
    "y_pred = np.array([[-18.6, 0.51], [2.94, -12.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b62a5f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da3b490a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.33667218, 7.71247424])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9407e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
